{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dataset\n",
    "train = datasets.MNIST(root= '../datasets', download = True, train = True, transform = ToTensor())\n",
    "train_loader = DataLoader(train, batch_size = 32)\n",
    "train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model class\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # CNN\n",
    "            nn.Conv2d(1, 32, (3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3,3)),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Dense\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * (28-6) * (28-6), 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance for nn\n",
    "model = ImageClassifier().to('cuda')\n",
    "\n",
    "opt = Adam(model.parameters(), lr = 1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | loss: 0.010230892337858677\n",
      "Epoch: 1 | loss: 0.005136302672326565\n",
      "Epoch: 2 | loss: 0.0011571476934477687\n",
      "Epoch: 3 | loss: 0.0004669378977268934\n",
      "Epoch: 4 | loss: 0.0012390125775709748\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    for data in train_loader:\n",
    "        x, y = data\n",
    "\n",
    "        # send to gpu\n",
    "        x, y = x.to('cuda'), y.to('cuda')\n",
    "\n",
    "        # make prediction\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # calc loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # backprop\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    \n",
    "    print(f'Epoch: {epoch} | loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "from torch import save, load\n",
    "\n",
    "with open('model_state.pt', 'wb') as f:\n",
    "    save(model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation of model\n",
    "# get dataset\n",
    "test = datasets.MNIST(root= '../datasets', download = True, train = False, transform = ToTensor())\n",
    "test_loader = DataLoader(train, batch_size = 32)\n",
    "train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9965\n"
     ]
    }
   ],
   "source": [
    "true_ans = 0\n",
    "false_ans = 0\n",
    "for data in train_loader:\n",
    "    x, y = data\n",
    "    # send to gpu\n",
    "    x, y = x.to('cuda'), y.to('cuda')\n",
    "\n",
    "    # make prediction\n",
    "    y_pred = model(x)\n",
    "\n",
    "    for pred, ans in zip(y_pred, y):\n",
    "        if torch.argmax(pred) == ans:\n",
    "            true_ans += 1\n",
    "        else:\n",
    "            false_ans += 1\n",
    "\n",
    "print(f'Accuracy is: {true_ans/(true_ans + false_ans)}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Trying own input\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feeding own data\n",
    "def predict_number(path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),   # Resize to 28x28 pixels\n",
    "        transforms.Grayscale(),        # Convert to grayscale\n",
    "        transforms.ToTensor()           # Convert PIL image to PyTorch tensor\n",
    "    ])\n",
    "\n",
    "    # Load the image and apply the transformation\n",
    "    image = Image.open(path)\n",
    "    image = transform(image).to('cuda')\n",
    "\n",
    "    # show image\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    plt.imshow(torch.reshape(image, (28, 28)).cpu().numpy())\n",
    "\n",
    "    # prepare data\n",
    "    image = torch.reshape(image, (1, 1, 28, 28))\n",
    "\n",
    "    # make pred\n",
    "    pred = model(image)\n",
    "    return torch.argmax(pred).item()\n",
    "    \n",
    "\n",
    "predict_number('./img.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
